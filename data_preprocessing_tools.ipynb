{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArifaAsha/LearningML/blob/main/data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Svu7Mp3y16vo"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Data.csv')\n",
        "X = dataset.iloc[:, :-1]  # -1 = last column\n",
        "y = dataset.iloc[:, -1:] #"
      ],
      "metadata": {
        "id": "6BwNUgG92arV"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "HQSj8qwZ4hB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "vbZJO6e_4i_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "X = np.array(X)\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(X[:, 1:3])\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
        "\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMk29ckE4xy-",
        "outputId": "7272331c-58ed-49b7-8032-b8b81f11fc2b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zgB_v0Dkjtz",
        "outputId": "ddd238fd-fdef-419c-8ac7-e785d4e97074"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('pima-indians-diabetes.csv')\n",
        "\n",
        "# Identify missing data (assumes that missing data is represented as NaN)\n",
        "missing_data = dataset.isna()\n",
        "X = dataset.iloc[:, :-1]  # -1 = last column\n",
        "y = dataset.iloc[:, -1:] #\n",
        "# print(X)\n",
        "\n",
        "# Print the number of missing entries in each column\n",
        "print(missing_data.sum())\n",
        "\n",
        "# imputer = SimpleImputer(strategy='median')\n",
        "# dataset.iloc[:, 0] = imputer.fit_transform(dataset.iloc[:, 0].values.reshape(-1, 1))\n",
        "\n",
        "# Configure an instance of the SimpleImputer class\n",
        "imputer = SimpleImputer(missing_values=np.NAN, strategy='mean')\n",
        "\n",
        "\n",
        "#Fit the imputer on the DataFrame\n",
        "imputer.fit(X[1:7])\n",
        "\n",
        "# Apply the transform to the DataFrame\n",
        "X[1:7] = imputer.transform(X[1:7])\n",
        "\n",
        "#Print your updated matrix of features\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6TZjiHvjU96",
        "outputId": "189e1c17-3b31-403e-84e3-028d3fb05868"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6        0\n",
            "148      0\n",
            "72       0\n",
            "35       0\n",
            "0        0\n",
            "33.6     0\n",
            "0.627    0\n",
            "50       0\n",
            "1        0\n",
            "dtype: int64\n",
            "        6    148    72    35      0  33.6  0.627    50\n",
            "0     1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0\n",
            "1     8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0\n",
            "2     1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0\n",
            "3     0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0\n",
            "4     5.0  116.0  74.0   0.0    0.0  25.6  0.201  30.0\n",
            "..    ...    ...   ...   ...    ...   ...    ...   ...\n",
            "762  10.0  101.0  76.0  48.0  180.0  32.9  0.171  63.0\n",
            "763   2.0  122.0  70.0  27.0    0.0  36.8  0.340  27.0\n",
            "764   5.0  121.0  72.0  23.0  112.0  26.2  0.245  30.0\n",
            "765   1.0  126.0  60.0   0.0    0.0  30.1  0.349  47.0\n",
            "766   1.0   93.0  70.0  31.0    0.0  30.4  0.315  23.0\n",
            "\n",
            "[767 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "dataset = pd.read_csv('Data.csv')\n",
        "X = dataset.iloc[:, :-1]  # -1 = last column\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])],remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-s1DPVrr48h",
        "outputId": "4a5aa1bb-2c6d-4457-fd01-66b3ec95de97"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0e+00 0.0e+00 0.0e+00 4.4e+01 7.2e+04]\n",
            " [0.0e+00 0.0e+00 1.0e+00 2.7e+01 4.8e+04]\n",
            " [0.0e+00 1.0e+00 0.0e+00 3.0e+01 5.4e+04]\n",
            " [0.0e+00 0.0e+00 1.0e+00 3.8e+01 6.1e+04]\n",
            " [0.0e+00 1.0e+00 0.0e+00 4.0e+01     nan]\n",
            " [1.0e+00 0.0e+00 0.0e+00 3.5e+01 5.8e+04]\n",
            " [0.0e+00 0.0e+00 1.0e+00     nan 5.2e+04]\n",
            " [1.0e+00 0.0e+00 0.0e+00 4.8e+01 7.9e+04]\n",
            " [0.0e+00 1.0e+00 0.0e+00 5.0e+01 8.3e+04]\n",
            " [1.0e+00 0.0e+00 0.0e+00 3.7e+01 6.7e+04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "dataset = pd.read_csv('Data.csv')\n",
        "y = dataset.iloc[:, -1:] #\n",
        "\n",
        "le = LabelEncoder()\n",
        "y =le.fit_transform(y)\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNpa4lyqvqlb",
        "outputId": "37aee4d8-3832-4eb3-be41-3290b65b59fb"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('titanic.csv')\n",
        "\n",
        "X = dataset[:]\n",
        "y = dataset['Survived']\n",
        "\n",
        "categorical_features = ['Sex', 'Embarked', 'Pclass']\n",
        "\n",
        "# Implement an instance of the ColumnTransformer class\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), categorical_features)], remainder='passthrough')\n",
        "\n",
        "# Apply the fit_transform method on the instance of ColumnTransformer\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "# Use LabelEncoder to encode binary categorical data\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(dataset['Survived'])\n",
        "\n",
        "# Print the updated matrix of features and the dependent variable vector\n",
        "print(X)\n",
        "print(y)\n"
      ],
      "metadata": {
        "id": "xxRxPY70yGac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
      ],
      "metadata": {
        "id": "E3j-ufUP2tkb"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Iris dataset\n",
        "dataset = pd.read_csv('Iris.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = dataset.drop(columns= 'Species')\n",
        "y = dataset['Species']\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02YfMI3q2uze",
        "outputId": "bae88ea2-e4d3-422a-cd87-33e66b81974a"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "0      1            5.1           3.5            1.4           0.2\n",
            "1      2            4.9           3.0            1.4           0.2\n",
            "2      3            4.7           3.2            1.3           0.2\n",
            "3      4            4.6           3.1            1.5           0.2\n",
            "4      5            5.0           3.6            1.4           0.2\n",
            "..   ...            ...           ...            ...           ...\n",
            "145  146            6.7           3.0            5.2           2.3\n",
            "146  147            6.3           2.5            5.0           1.9\n",
            "147  148            6.5           3.0            5.2           2.0\n",
            "148  149            6.2           3.4            5.4           2.3\n",
            "149  150            5.9           3.0            5.1           1.8\n",
            "\n",
            "[150 rows x 5 columns]\n",
            "0         Iris-setosa\n",
            "1         Iris-setosa\n",
            "2         Iris-setosa\n",
            "3         Iris-setosa\n",
            "4         Iris-setosa\n",
            "            ...      \n",
            "145    Iris-virginica\n",
            "146    Iris-virginica\n",
            "147    Iris-virginica\n",
            "148    Iris-virginica\n",
            "149    Iris-virginica\n",
            "Name: Species, Length: 150, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
      ],
      "metadata": {
        "id": "4qui08guEA2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}